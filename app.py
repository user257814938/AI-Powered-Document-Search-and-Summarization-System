# Objectif ‚Äî Construire une app Streamlit RAG CPU-friendly (upload ‚Üí chunking ‚Üí embeddings ‚Üí FAISS ‚Üí recherche ‚Üí r√©sum√©)

# √âtape 1 ‚Äî Importer les biblioth√®ques et fonctions utilitaires
import tempfile                                                                   # import : charger un module | tempfile : g√©rer des dossiers temporaires
from pathlib import Path                                                          # from : importer depuis un module | pathlib : gestion des chemins | import Path : classe chemin
from typing import List                                                           # from : importer depuis un module | typing : types Python | import List : liste typ√©e
import streamlit as st                                                            # import : charger un module | streamlit : UI web Python | as st : alias local

from utils import (                                                               # from : importer depuis un module | utils : fichier utilitaire local | import (...) : fonctions/classes utilis√©es
    IndexedChunk,                                                                 # IndexedChunk : dataclass (texte + ids)
    build_embedder,                                                               # build_embedder : construire l‚Äôencodeur d‚Äôembeddings
    build_faiss_index,                                                            # build_faiss_index : cr√©er un index FAISS
    build_summarizer,                                                             # build_summarizer : construire le mod√®le de r√©sum√©
    build_tokenizer,                                                              # build_tokenizer : construire le tokenizer
    chunk_text,                                                                   # chunk_text : d√©couper le texte en chunks
    encode_chunks,                                                                # encode_chunks : encoder chaque chunk en embedding
    extract_text,                                                                 # extract_text : extraire le texte depuis un fichier
    search,                                                                       # search : chercher dans FAISS
    summarize_chunks,                                                             # summarize_chunks : r√©sumer une liste de chunks
)

# √âtape 2 ‚Äî D√©finir un dossier cache local
def get_cache_dir() -> Path:                                                      # def : d√©finir une fonction | get_cache_dir : nom | -> Path : retourne un chemin
    base = Path(tempfile.gettempdir()) / "rag_streamlit"                          # base : dossier cache | = : affectation | Path(tempfile.gettempdir()) : dossier temporaire syst√®me | / "rag_streamlit" : sous-dossier
    base.mkdir(parents=True, exist_ok=True)                                       # base.mkdir : cr√©er le dossier | parents=True : cr√©er les parents | exist_ok=True : ignorer si existe
    return base                                                                   # return : renvoyer le chemin cache

# √âtape 3 ‚Äî Mettre en cache les ressources lourdes (tokenizer, embedder, summarizer)
@st.cache_resource(show_spinner=False)                                           # st.cache_resource : cache persistant Streamlit | show_spinner=False : pas de spinner auto
def get_tokenizer():                                                             # def : d√©finir une fonction | get_tokenizer : nom
    return build_tokenizer()                                                     # return : renvoyer | build_tokenizer() : instance tokenizer

@st.cache_resource(show_spinner=False)                                           # st.cache_resource : cache persistant Streamlit
def get_embedder():                                                              # def : d√©finir une fonction | get_embedder : nom
    return build_embedder()                                                      # return : renvoyer | build_embedder() : instance embedder

@st.cache_resource(show_spinner=False)                                           # st.cache_resource : cache persistant Streamlit
def get_summarizer():                                                            # def : d√©finir une fonction | get_summarizer : nom
    return build_summarizer()                                                    # return : renvoyer | build_summarizer() : instance summarizer

# √âtape 4 ‚Äî Configurer la page Streamlit et le layout
st.set_page_config(page_title="Recherche + R√©sum√© (CPU)", layout="wide")         # st.set_page_config : configurer la page | page_title : titre onglet | layout="wide" : mode large
st.title("üîé Recherche s√©mantique + r√©sum√© (CPU-friendly)")                      # st.title : titre principal | "üîé ..." : texte affich√©

# √âtape 5 ‚Äî Construire la sidebar (upload + hyperparam√®tres)
st.sidebar.header("üìÇ Upload & Pr√©paration")                                     # st.sidebar.header : titre sidebar | "üìÇ ..." : texte
uploaded_file = st.sidebar.file_uploader(                                        # uploaded_file : fichier upload√© | = : affectation | st.sidebar.file_uploader : widget upload
    "Choisir un fichier",                                                        # "Choisir un fichier" : label du widget
    type=["txt", "pdf", "docx"],                                                 # type=[...] : extensions autoris√©es
)
chunk_size = st.sidebar.slider(                                                  # chunk_size : taille chunk | = : affectation | st.sidebar.slider : widget slider
    "Taille des chunks (tokens)",                                                # label : texte du slider
    min_value=100,                                                               # min_value : valeur min
    max_value=400,                                                               # max_value : valeur max
    value=250,                                                                   # value : valeur par d√©faut
    step=25,                                                                     # step : pas
)
overlap = st.sidebar.slider(                                                     # overlap : recouvrement | = : affectation | slider : widget
    "Overlap (tokens)",                                                          # label
    min_value=0,                                                                 # min_value : min
    max_value=100,                                                               # max_value : max
    value=30,                                                                    # value : d√©faut
    step=10,                                                                     # step : pas
)
batch_size = st.sidebar.select_slider(                                           # batch_size : taille batch embeddings | = : affectation | select_slider : widget
    "Batch embeddings",                                                          # label
    options=[2, 4, 8],                                                           # options : valeurs possibles
    value=4,                                                                     # value : d√©faut
)
top_k = st.sidebar.slider(                                                       # top_k : nb r√©sultats | = : affectation | slider : widget
    "Top-k r√©sultats",                                                           # label
    min_value=1,                                                                 # min_value : min
    max_value=10,                                                                # max_value : max
    value=5,                                                                     # value : d√©faut
)

# √âtape 6 ‚Äî Initialiser l‚Äô√©tat Streamlit (index, chunks, embeddings)
if "index" not in st.session_state:                                              # if : condition | "index" not in st.session_state : test d‚Äôinitialisation
    st.session_state.index = None                                                # st.session_state.index : √©tat index FAISS | = None : pas encore construit
    st.session_state.chunks: List[IndexedChunk] = []                             # st.session_state.chunks : liste typ√©e | = [] : vide
    st.session_state.embeddings = None                                           # st.session_state.embeddings : embeddings doc | = None : non calcul√©s

# √âtape 7 ‚Äî D√©finir la routine d‚Äôupload + indexation
def handle_upload():                                                             # def : d√©finir une fonction | handle_upload : callback sidebar
    if not uploaded_file:                                                        # if : condition | not uploaded_file : aucun fichier upload√©
        st.warning("Uploadez un fichier pour d√©marrer.")                         # st.warning : alerte utilisateur | "..." : message
        return                                                                   # return : sortir de la fonction

    cache_dir = get_cache_dir()                                                  # cache_dir : dossier cache | = : affectation | get_cache_dir() : appel
    dest_path = cache_dir / uploaded_file.name                                   # dest_path : chemin fichier cache | = : affectation | cache_dir / name : concat√©nation Path
    with dest_path.open("wb") as f:                                              # with : contexte fichier | dest_path.open("wb") : ouvrir en √©criture binaire
        f.write(uploaded_file.getbuffer())                                       # f.write : √©crire bytes | uploaded_file.getbuffer() : contenu upload√©

    with st.spinner("Extraction du texte..."):                                   # with : spinner UI | "Extraction..." : message spinner
        text = extract_text(dest_path)                                           # text : texte extrait | = : affectation | extract_text(dest_path) : extraction

    tokenizer = get_tokenizer()                                                  # tokenizer : tokenizer cach√© | = : affectation | get_tokenizer() : appel cache
    with st.spinner("D√©coupage en chunks..."):                                   # with : spinner UI | "D√©coupage..." : message
        chunks_text = chunk_text(                                                # chunks_text : liste de chunks | = : affectation | chunk_text(...) : d√©coupe
            text,                                                                # text : texte source
            tokenizer=tokenizer,                                                 # tokenizer=tokenizer : tokenizer utilis√©
            chunk_size=chunk_size,                                               # chunk_size=chunk_size : taille choisie via slider
            overlap=overlap,                                                     # overlap=overlap : recouvrement choisi
        )

    if not chunks_text:                                                          # if : condition | not chunks_text : liste vide
        st.error("Aucun texte d√©tect√© apr√®s d√©coupe.")                           # st.error : message erreur
        return                                                                   # return : sortir

    embedder = get_embedder()                                                    # embedder : mod√®le embeddings | = : affectation | get_embedder() : appel cache
    with st.spinner("Calcul des embeddings (CPU)..."):                           # with : spinner UI | "Calcul..." : message
        embeddings = encode_chunks(                                              # embeddings : matrice embeddings | = : affectation | encode_chunks(...) : encodage
            chunks_text,                                                         # chunks_text : segments texte
            embedder=embedder,                                                   # embedder=embedder : encodeur
            batch_size=batch_size,                                               # batch_size=batch_size : taille batch
        )

    with st.spinner("Construction de l'index FAISS..."):                         # with : spinner UI | "Construction..." : message
        index = build_faiss_index(embeddings)                                    # index : FAISS index | = : affectation | build_faiss_index(embeddings) : construction

    st.session_state.index = index                                               # st.session_state.index : stocker index | = : affectation
    st.session_state.embeddings = embeddings                                     # st.session_state.embeddings : stocker embeddings | = : affectation
    st.session_state.chunks = [                                                  # st.session_state.chunks : stocker chunks enrichis | = : affectation | [...] : list comprehension
        IndexedChunk(text=chunk, doc_id=uploaded_file.name, chunk_id=i)          # IndexedChunk(...) : construire un item | text : contenu | doc_id : nom fichier | chunk_id : id chunk
        for i, chunk in enumerate(chunks_text)                                   # for : boucle comprehension | enumerate(chunks_text) : (index, chunk)
    ]
    st.success(f"Index construit avec {len(chunks_text)} chunks.")               # st.success : message succ√®s | f"...{len(...) }..." : nb chunks

# √âtape 8 ‚Äî Bouton sidebar pour lancer l‚Äôindexation
st.sidebar.button("Indexer le document", on_click=handle_upload)                 # st.sidebar.button : bouton | "Indexer..." : label | on_click=handle_upload : callback

# √âtape 9 ‚Äî Zone de requ√™te utilisateur
st.subheader("Requ√™te")                                                          # st.subheader : sous-titre section | "Requ√™te" : texte
query = st.text_input("Texte de la requ√™te")                                     # query : texte requ√™te | = : affectation | st.text_input : champ input

# √âtape 10 ‚Äî Lancer la recherche et le r√©sum√©
if st.button("Lancer la recherche"):                                                        # if : condition | st.button(...) : bouton principal
    if not st.session_state.index:                                                          # if : condition | not index : aucun index
        st.error("Aucun index n'est disponible. Uploadez et indexez un document d'abord.")  # st.error : message erreur
    elif not query.strip():                                                                 # elif : autre condition | not query.strip() : requ√™te vide
        st.warning("La requ√™te est vide.")                                                  # st.warning : avertissement
    else:
        embedder = get_embedder()                                                # embedder : r√©cup√©rer embedder | = : affectation
        query_emb = embedder.encode(                                             # query_emb : embedding requ√™te | = : affectation | embedder.encode(...) : encodage
            [query],                                                             # [query] : liste d‚Äôune requ√™te
            normalize_embeddings=True,                                           # normalize_embeddings=True : normaliser embeddings
            convert_to_numpy=True,                                               # convert_to_numpy=True : sortie NumPy
        ).astype("float32")                                                      # .astype("float32") : convertir dtype float32

        scores, idxs = search(query_emb, st.session_state.index, top_k=top_k)    # scores, idxs : r√©sultats FAISS | = : affectation | search(...) : recherche | top_k=top_k : nb r√©sultats
        best_scores = scores[0]                                                  # best_scores : scores top-k | = : affectation | scores[0] : premi√®re requ√™te
        best_idxs = idxs[0]                                                      # best_idxs : indices top-k | = : affectation | idxs[0] : premi√®re requ√™te

        retrieved = []                                                           # retrieved : liste r√©sultats | = : affectation | [] : vide
        for score, idx in zip(best_scores, best_idxs):                           # for : boucle | zip(...) : pairs (score, index)
            if idx == -1:                                                        # if : condition | idx == -1 : r√©sultat vide FAISS
                continue                                                         # continue : passer au suivant
            chunk = st.session_state.chunks[idx]                                 # chunk : chunk r√©cup√©r√© | = : affectation | st.session_state.chunks[idx] : acc√®s par index
            retrieved.append((chunk, score))                                     # retrieved.append : ajouter | (chunk, score) : tuple r√©sultat

        if not retrieved:                                                        # if : condition | not retrieved : aucun r√©sultat
            st.info("Aucun r√©sultat retourn√©.")                                  # st.info : information UI
        else:
            st.markdown("### R√©sultats")                                         # st.markdown : titre markdown
            for rank, (chunk, score) in enumerate(retrieved, start=1):           # for : boucle | enumerate(..., start=1) : ranking √† partir de 1
                st.write(f"**#{rank}** ‚Äî distance L2: {score:.4f}")              # st.write : afficher texte | f"...{score:.4f}" : score format√©
                st.caption(f"{chunk.doc_id} | chunk {chunk.chunk_id}")           # st.caption : petit texte | doc_id + chunk_id
                st.code(chunk.text)                                              # st.code : afficher code/texte monospac√© | chunk.text : contenu

            summarizer = get_summarizer()                                        # summarizer : mod√®le r√©sum√© | = : affectation | get_summarizer() : appel cache
            with st.spinner("G√©n√©ration du r√©sum√© (t5-small, CPU)..."):          # with : spinner UI | "G√©n√©ration..." : message
                summary = summarize_chunks(                                      # summary : r√©sum√© final | = : affectation | summarize_chunks(...) : r√©sum√©
                    [item[0] for item in retrieved],                             # [item[0] for item in retrieved] : liste des chunks sans scores
                    summarizer=summarizer,                                       # summarizer=summarizer : mod√®le de r√©sum√©
                )
            st.markdown("### R√©sum√© synth√©tique")                                # st.markdown : titre markdown
            st.success(summary)                                                  # st.success : afficher r√©sum√© dans un bloc succ√®s
